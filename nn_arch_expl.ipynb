{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_arch_expl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV8THtbo6K6Y",
        "colab_type": "text"
      },
      "source": [
        "Let's start with the Feed-Forward analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU2jxk3JRZ7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.decomposition\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist_data, mnist_info = tfds.load('mnist', with_info=True)\n",
        "print(mnist_info)\n",
        "mnist_train_x = np.asarray([instance['image']/255 for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "mnist_train_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "\n",
        "mnist_test_x = np.asarray([instance['image']/255 for instance in tfds.as_numpy(mnist_data['test'])])\n",
        "mnist_test_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['test'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CdCs9OW6Jvf",
        "colab_type": "text"
      },
      "source": [
        "First, we need to decide the number of neurons of each hidden layer. The thumb rule says that it should be between the input and output size. With this in mind, let's test and verify which brings us the best results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQcep4gbRcIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neurons = [100, 200, 300, 400, 500, 600, 700]\n",
        "modelsResults = []\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "\n",
        "for i in range(len(neurons)):\n",
        "  filename = 'mnist_two_layers_'+str(neurons[i])+'_best.h5'\n",
        "  modelname = 'mnist_ff_two_layers_'+str(neurons[i])\n",
        "  checkpoint_two_layers = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_two_layers_model = tf.keras.Sequential(name=modelname)\n",
        "  mnist_two_layers_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_two_layers_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  mnist_two_layers_model.add(tf.keras.layers.Dense(neurons[i], activation='tanh', name='test'))\n",
        "  mnist_two_layers_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_two_layers_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_two_layers_model.summary()\n",
        "\n",
        "  mnist_two_layers_model_train = mnist_two_layers_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint_two_layers], epochs=10000, batch_size=256)\n",
        "  mnist_two_layers_model.load_weights(filename)\n",
        "  loss, acc = mnist_two_layers_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelsResults += [[loss, acc]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_i4UjQz8Uqe",
        "colab_type": "text"
      },
      "source": [
        "Let's plot and check the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1-YnwVA1thz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultsArray = np.array(modelsResults)\n",
        "resultsArray = np.array([[0.1103, 0.9678], [0.0981, 0.9709], [0.0957, 0.9706], [0.0960, 0.9715], [0.1084,0.9681], [0.1096, 0.9686], [0.1080,0.9688]])\n",
        "# best result: neurons = 400\n",
        "print(\"Best result:\", neurons[np.argmax(resultsArray, axis=0)[1]])\n",
        "#print(resultsArray[:,1])\n",
        "\n",
        "accuracyMaxIndex = np.argmax(resultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(resultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Neurons Analysis - Loss')\n",
        "loss_ax.plot(neurons, resultsArray[:,0] , '-r', label='Train')\n",
        "loss_ax.plot(neurons[lossMinIndex], resultsArray[:,0][lossMinIndex], \"X\")\n",
        "loss_ax.set_xlabel(\"Neurons\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Neurons Analysis - Accuracy')\n",
        "acc_ax.plot(neurons, resultsArray[:,1], '-g', label='Train')\n",
        "acc_ax.plot(neurons[accuracyMaxIndex], resultsArray[:,1][accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Neurons\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUZXvk4576Sn",
        "colab_type": "text"
      },
      "source": [
        "The next step is to decide the number of hidden layers of our model. \n",
        "Let's test and verify which brings us the best balance of accuracy and complexity without overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heayJQierFAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test between 2 - 7 layers\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "modelLayersResults = []\n",
        "for i in range(2,8):\n",
        "  filename = 'mnist_'+str(i)+'_layers_best.h5'\n",
        "  modelname = 'mnist_ff_'+str(i)+'_layers'\n",
        "  mnist_model = tf.keras.Sequential(name=modelname)\n",
        "  mnist_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  for j in range(i-1):\n",
        "    mnist_model.add(tf.keras.layers.Dense(neurons[np.argmax(resultsArray, axis=0)[1]], activation='tanh', name='hidden_layer_'+str(j+1)))\n",
        "  mnist_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_model.summary()\n",
        "\n",
        "  mnist_model.load_weights(filename)\n",
        "  loss, acc = mnist_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelLayersResults += [[loss, acc]]\n",
        "\n",
        "for result in modelLayersResults:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncb_trozs18j",
        "colab_type": "text"
      },
      "source": [
        "Let's plot and check the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7CfQ9gvs5gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layerResultsArray = np.array(modelLayersResults)\n",
        "# best result: 4 hidden layers\n",
        "print(\"Best result:\", np.argmax(layerResultsArray, axis=0)[1] + 1)\n",
        "\n",
        "accuracyMaxIndex = np.argmax(layerResultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(layerResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Hidden Layers Analysis - Loss')\n",
        "loss_ax.plot(np.arange(1,7), layerResultsArray[:,0] , '-r', label='Train')\n",
        "loss_ax.plot(lossMinIndex+1, layerResultsArray[:,0][lossMinIndex], \"X\")\n",
        "loss_ax.set_xlabel(\"Hidden Layers\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Hidden Layers Analysis - Accuracy')\n",
        "acc_ax.plot(np.arange(1,7), layerResultsArray[:,1], '-g', label='Train')\n",
        "acc_ax.plot(accuracyMaxIndex+1, layerResultsArray[:,1][accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Hidden Layers\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u319Pj2xIj8J",
        "colab_type": "text"
      },
      "source": [
        "Now let's explore the Regularization methods. \n",
        "The regularization factor should be between 1 and the number of instances of the dataset. Let's do some testing in l1 and l2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyCG-_n_I45F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training dataset contains 60000 instances, so we'll vary the parameter between 1 and 600000\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "modelRegularizationResults = []\n",
        "for i in range(0,100, 10):\n",
        "  filename = 'mnist_4_layers_+'+str(i)+'best.h5'\n",
        "  modelname = 'mnist_ff_4_layers_'+str(i)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_model = tf.keras.Sequential(name=modelname)\n",
        "  mnist_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(i/100), name='hidden_layer_0'))\n",
        "  for j in range(3):\n",
        "    mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', name='hidden_layer_'+str(j+1)))\n",
        "\n",
        "  mnist_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_model.summary()\n",
        "  mnist_model_train = mnist_model.fit(mnist_train_x[:5000], mnist_train_y[:5000], validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_model.load_weights(filename)\n",
        "  loss, acc = mnist_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelRegularizationResults += [[loss, acc]]\n",
        "  print(modelRegularizationResults)\n",
        "\n",
        "for result in modelRegularizationResults:\n",
        "  print(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqzz9_NwZrxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "modelRegularizationResultsL1 = []\n",
        "for i in range(0,100, 10):\n",
        "  filename = 'mnist_4_layers_L1_+'+str(i)+'best.h5'\n",
        "  modelname = 'mnist_ff_4_layers_L1_'+str(i)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_model = tf.keras.Sequential(name=modelname)\n",
        "  mnist_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1(i/100), name='hidden_layer_0'))\n",
        "  for j in range(3):\n",
        "    mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', name='hidden_layer_'+str(j+1)))\n",
        "\n",
        "  mnist_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_model.summary()\n",
        "  mnist_model_train = mnist_model.fit(mnist_train_x[:5000], mnist_train_y[:5000], validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_model.load_weights(filename)\n",
        "  loss, acc = mnist_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelRegularizationResultsL1 += [[loss, acc]]\n",
        "  print(modelRegularizationResultsL1)\n",
        "\n",
        "for result in modelRegularizationResultsL1:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0t1k0O8gi12",
        "colab_type": "text"
      },
      "source": [
        "Let's plot and check the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPVKZF3VgQgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1regularizationResultsArray = np.array(modelRegularizationResultsL1)\n",
        "L2regularizationResultsArray = np.array(modelRegularizationResults)\n",
        "\n",
        "\n",
        "regLimits = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "# best result: 0-0.1 \n",
        "print(\"Best result:\", regLimits[np.argmax(regularizationResultsArray, axis=0)[1]])\n",
        "\n",
        "L1accuracyMaxIndex = np.argmax(L1regularizationResultsArray, axis=0)[1]\n",
        "L1lossMinIndex = np.argmin(L1regularizationResultsArray, axis=0)[0]\n",
        "L2accuracyMaxIndex = np.argmax(L2regularizationResultsArray, axis=0)[1]\n",
        "L2lossMinIndex = np.argmin(L2regularizationResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Regularization Broad Analysis - Loss')\n",
        "loss_ax.plot(regLimits, L1regularizationResultsArray[:,0] , '-g', label='L1')\n",
        "loss_ax.plot(regLimits, L2regularizationResultsArray[:,0] , '-b', label='L2')\n",
        "\n",
        "\n",
        "loss_ax.set_xlabel(\"Regularization Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Regularization Broad Analysis - Accuracy')\n",
        "acc_ax.plot(regLimits, L1regularizationResultsArray[:,1] , '-g', label='L1')\n",
        "acc_ax.plot(regLimits, L2regularizationResultsArray[:,1] , '-b', label='L2')\n",
        "\n",
        "acc_ax.set_xlabel(\"Regularization Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_9ROo0AoHZW",
        "colab_type": "text"
      },
      "source": [
        "Now we need to shorten the intervals in order to find the ideal value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUXiFFi2oMS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "modelRegularizationResultsL1 = []\n",
        "for i in range(0,100, 10):\n",
        "  filename = 'mnist_4_layers_L1_+'+str(i/1000)+'best.h5'\n",
        "  modelname = 'mnist_ff_4_layers_L1_'+str(i/1000)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_model = tf.keras.Sequential(name=modelname)\n",
        "  mnist_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  for j in range(4):\n",
        "    mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1(i/1000), name='hidden_layer_'+str(j+1)))\n",
        "  mnist_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_model.summary()\n",
        "  mnist_model_train = mnist_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_model.load_weights(filename)\n",
        "  loss, acc = mnist_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelRegularizationResultsL1 += [[loss, acc]]\n",
        "  print(modelRegularizationResultsL1)\n",
        "\n",
        "for result in modelRegularizationResultsL1:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDew113DuUyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "modelRegularizationResultsL2 = []\n",
        "for i in range(0,100, 10):\n",
        "  filename = 'mnist_4_layers_L2_+'+str(i/1000)+'best.h5'\n",
        "  modelname = 'mnist_ff_4_layers_L2_'+str(i/1000)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_model = tf.keras.Sequential(name=modelname)\n",
        "  mnist_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1(i/1000), name='hidden_layer_0'))\n",
        "  for j in range(3):\n",
        "    mnist_model.add(tf.keras.layers.Dense(400, activation='tanh', name='hidden_layer_'+str(j+1)))\n",
        "\n",
        "  mnist_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_model.summary()\n",
        "  mnist_model_train = mnist_model.fit(mnist_train_x[:5000], mnist_train_y[:5000], validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_model.load_weights(filename)\n",
        "  loss, acc = mnist_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelRegularizationResultsL2 += [[loss, acc]]\n",
        "  print(modelRegularizationResultsL2)\n",
        "\n",
        "for result in modelRegularizationResultsL2:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND-E8MTc1NWK",
        "colab_type": "text"
      },
      "source": [
        "Let's now evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xo4bn331QhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1regularizationResultsArray = np.array(modelRegularizationResultsL1)\n",
        "L2regularizationResultsArray = np.array(modelRegularizationResultsL2)\n",
        "\n",
        "\n",
        "regLimits = [0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
        "# best result: 0-0.1 \n",
        "print(\"Best result:\", regLimits[np.argmax(regularizationResultsArray, axis=0)[1]])\n",
        "\n",
        "L1accuracyMaxIndex = np.argmax(L1regularizationResultsArray, axis=0)[1]\n",
        "L1lossMinIndex = np.argmin(L1regularizationResultsArray, axis=0)[0]\n",
        "L2accuracyMaxIndex = np.argmax(L2regularizationResultsArray, axis=0)[1]\n",
        "L2lossMinIndex = np.argmin(L2regularizationResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Regularization Detail Analysis - Loss')\n",
        "loss_ax.plot(regLimits, L1regularizationResultsArray[:,0] , '-g', label='L1')\n",
        "loss_ax.plot(regLimits, L2regularizationResultsArray[:,0] , '-b', label='L2')\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L1regularizationResultsArray[:,0][L1lossMinIndex], \"X\")\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L2regularizationResultsArray[:,0][L2lossMinIndex], \"X\")\n",
        "\n",
        "loss_ax.set_xlabel(\"Regularization Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Regularization Detail Analysis - Accuracy')\n",
        "acc_ax.plot(regLimits, L1regularizationResultsArray[:,1] , '-g', label='L1')\n",
        "acc_ax.plot(regLimits, L2regularizationResultsArray[:,1] , '-b', label='L2')\n",
        "#acc_ax.plot(regLimits[L1accuracyMaxIndex], L1regularizationResultsArray[:,1][L1accuracyMaxIndex], \"X\")\n",
        "#acc_ax.plot(regLimits[L2accuracyMaxIndex], L2regularizationResultsArray[:,1][L2accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Regularization Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWXcqHPcH6ag",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMR9nhlCIHIO",
        "colab_type": "text"
      },
      "source": [
        "Once again, we begin by deciding the number of neurons of each hidden layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vh4oLNzIImi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neurons = [100, 200, 300, 400, 500, 600, 700]\n",
        "modelsResults = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqRImwTVIKlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "\n",
        "for i in range(len(neurons)):\n",
        "  mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "  mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Dense(neurons[i], activation='relu', name='hl1'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model.summary()\n",
        "  \n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_model_train = mnist_conv_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelsResults += [[loss, acc]]\n",
        "  print('Accuracy: {}'.format(acc))\n",
        "  print('Loss: {}'.format(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8rrOrT7IQ4t",
        "colab_type": "text"
      },
      "source": [
        "Let's plot and check the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex7z-venIPyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "6b86a2ff-b491-4aaa-8d16-f533d4d08711"
      },
      "source": [
        "resultsArray = np.array(modelsResults)\n",
        "\n",
        "# best result: neurons = 700\n",
        "print(\"Best result:\", neurons[np.argmax(resultsArray, axis=0)[1]])\n",
        "\n",
        "accuracyMaxIndex = np.argmax(resultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(resultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Neurons Analysis - Loss')\n",
        "loss_ax.plot(neurons, resultsArray[:,0] , '-r', label='Train')\n",
        "loss_ax.plot(neurons[lossMinIndex], resultsArray[:,0][lossMinIndex], \"X\")\n",
        "loss_ax.set_xlabel(\"Neurons\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Neurons Analysis - Accuracy')\n",
        "acc_ax.plot(neurons, resultsArray[:,1], '-g', label='Train')\n",
        "acc_ax.plot(neurons[accuracyMaxIndex], resultsArray[:,1][accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Neurons\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best result: 700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpAzKHVzdw57",
        "colab_type": "text"
      },
      "source": [
        "The next step is deciding the number of hidden layers of our model. The best results were achieved with 700 neurons per layer, so we'll explore between 1 and 6 hidden layers, each with 700 neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgRwfQQd975",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelsResults = []\n",
        "for i in range(1,7):\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "  mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "  mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  for j in range(1,i+1):\n",
        "    mnist_conv_model.add(tf.keras.layers.Dense(700, activation='relu', name='hl'+str(j)))\n",
        "\n",
        "  mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model.summary()\n",
        "  \n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_model_train = mnist_conv_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  modelsResults += [[loss, acc]]\n",
        "  print('Accuracy: {}'.format(acc))\n",
        "  print('Loss: {}'.format(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0YZlxFnd_UF",
        "colab_type": "text"
      },
      "source": [
        "Let's now plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFvv7uGzd-2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resultsArray = np.array(modelsResults)\n",
        "resultsArray = np.array([[0.056138746440410614, 0.9811000227928162], [0.05270325392484665, 0.9837999939918518], [0.05080743879079819, 0.983299970626831], [0.05260307714343071, 0.9832000136375427], [0.05461176857352257, 0.9837999939918518], [0.05053083971142769, 0.984000027179718]])\n",
        "\n",
        "# best result: layers = 6\n",
        "layers = [1,2,3,4,5,6]\n",
        "print(\"Best result:\", layers[np.argmax(resultsArray, axis=0)[1]])\n",
        "#print(resultsArray[:,1])\n",
        "\n",
        "accuracyMaxIndex = np.argmax(resultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(resultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Number of Hidden Layers Analysis - Loss')\n",
        "loss_ax.plot(layers, resultsArray[:,0] , '-r', label='Train')\n",
        "loss_ax.plot(layers[lossMinIndex], resultsArray[:,0][lossMinIndex], \"X\")\n",
        "loss_ax.set_xlabel(\"Number of Hidden Layers\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Number of Hidden Layers Analysis - Accuracy')\n",
        "acc_ax.plot(layers, resultsArray[:,1], '-g', label='Train')\n",
        "acc_ax.plot(layers[accuracyMaxIndex], resultsArray[:,1][accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Number of Hidden Layers\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VMy1G954HL",
        "colab_type": "text"
      },
      "source": [
        "Let's now explore the usage of regularization. The network will have 6 hidden layers with 700 neurons each, the values previously found to deliever the best results.\n",
        "\n",
        "We begin with L2 Regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93prjdkV6OmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L2modelRegularizationResults = []\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "\n",
        "for i in range(0,100, 10):\n",
        "  mnist_conv_model_l2 = tf.keras.Sequential(name='mnist_cnn_l2'+str(i))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  for j in range(1,7):\n",
        "    mnist_conv_model_l2.add(tf.keras.layers.Dense(700, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(i/100), name='hl_'+str(j)))\n",
        "  \n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model_l2.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model_l2.summary()\n",
        "\n",
        "  filename = 'mnist_conv_6hl'+str(i)+'best.h5'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_model_l2_train = mnist_conv_model_l2.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model_l2.load_weights(filename)\n",
        "  loss, acc = mnist_conv_model_l2.evaluate(mnist_test_x, mnist_test_y)\n",
        "  L2modelRegularizationResults += [[loss, acc]]\n",
        "  print(L2modelRegularizationResults)\n",
        "\n",
        "for result in L2modelRegularizationResults:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFfPnp2r_1Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L2regularizationResultsArray = np.array(L2modelRegularizationResults)\n",
        "regLimits = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "\n",
        "# best result: 0-0.1 \n",
        "print(\"Best result:\", regLimits[np.argmax(L2regularizationResultsArray, axis=0)[1]])\n",
        "\n",
        "accuracyMaxIndex = np.argmax(L2regularizationResultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(L2regularizationResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('L2 Regularization Broad Analysis - Loss')\n",
        "loss_ax.plot(regLimits, L2regularizationResultsArray[:,0] , '-r', label='Train')\n",
        "loss_ax.plot(regLimits[lossMinIndex], L2regularizationResultsArray[:,0][lossMinIndex], \"X\")\n",
        "loss_ax.set_xlabel(\"Regularization Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('L2 Regularization Broad Analysis - Accuracy')\n",
        "acc_ax.plot(regLimits, L2regularizationResultsArray[:,1], '-g', label='Train')\n",
        "acc_ax.plot(regLimits[accuracyMaxIndex], L2regularizationResultsArray[:,1][accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Regularization Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUM845uXApUc",
        "colab_type": "text"
      },
      "source": [
        "Let's now try the L1 Regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zawjNVgCAzrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1modelRegularizationResults = []\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "\n",
        "for i in range(0,100, 10):\n",
        "  mnist_conv_model_l1 = tf.keras.Sequential(name='mnist_cnn_l1'+str(i))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  for j in range(1,7):\n",
        "    mnist_conv_model_l1.add(tf.keras.layers.Dense(700, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(i/100), name='hl_'+str(j)))\n",
        "  \n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model_l1.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model_l1.summary()\n",
        "\n",
        "  filename = 'mnist_conv_6hl'+str(i)+'best.h5'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_model_l1_train = mnist_conv_model_l1.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model_l1.load_weights(filename)\n",
        "  loss, acc = mnist_conv_model_l1.evaluate(mnist_test_x, mnist_test_y)\n",
        "  L1modelRegularizationResults += [[loss, acc]]\n",
        "  print(L1modelRegularizationResults)\n",
        "\n",
        "for result in L1modelRegularizationResults:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakMainCDyph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1regularizationResultsArray = np.array(L1modelRegularizationResults)\n",
        "regLimits = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "\n",
        "# best result: 0-0.1 \n",
        "print(\"Best result:\", regLimits[np.argmax(L1regularizationResultsArray, axis=0)[1]])\n",
        "\n",
        "accuracyMaxIndex = np.argmax(L1regularizationResultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(L1regularizationResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('L1 Regularization Broad Analysis - Loss')\n",
        "loss_ax.plot(regLimits, L1regularizationResultsArray[:,0] , '-r', label='Train')\n",
        "loss_ax.plot(regLimits[lossMinIndex], L1regularizationResultsArray[:,0][lossMinIndex], \"X\")\n",
        "loss_ax.set_xlabel(\"Regularization Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('L1 Regularization Broad Analysis - Accuracy')\n",
        "acc_ax.plot(regLimits, L1regularizationResultsArray[:,1], '-g', label='Train')\n",
        "acc_ax.plot(regLimits[accuracyMaxIndex], L1regularizationResultsArray[:,1][accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Regularization Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8u9hY-hKqXd",
        "colab_type": "text"
      },
      "source": [
        "Let's compare both regularizations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dttIvo7dKuGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1regularizationResultsArray = np.array(L1modelRegularizationResults)\n",
        "L2regularizationResultsArray = np.array(L2modelRegularizationResults)\n",
        "\n",
        "regLimits = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "# best result: 0-0.1 \n",
        "print(\"Best result:\", regLimits[np.argmax(regularizationResultsArray, axis=0)[1]])\n",
        "\n",
        "L1accuracyMaxIndex = np.argmax(L1regularizationResultsArray, axis=0)[1]\n",
        "L1lossMinIndex = np.argmin(L1regularizationResultsArray, axis=0)[0]\n",
        "L2accuracyMaxIndex = np.argmax(L2regularizationResultsArray, axis=0)[1]\n",
        "L2lossMinIndex = np.argmin(L2regularizationResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Regularization Broad Analysis - Loss')\n",
        "loss_ax.plot(regLimits, L1regularizationResultsArray[:,0] , '-g', label='L1')\n",
        "loss_ax.plot(regLimits, L2regularizationResultsArray[:,0] , '-b', label='L2')\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L1regularizationResultsArray[:,0][L1lossMinIndex], \"X\")\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L2regularizationResultsArray[:,0][L2lossMinIndex], \"X\")\n",
        "\n",
        "loss_ax.set_xlabel(\"Regularization Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Regularization Broad Analysis - Accuracy')\n",
        "acc_ax.plot(regLimits, L1regularizationResultsArray[:,1] , '-g', label='L1')\n",
        "acc_ax.plot(regLimits, L2regularizationResultsArray[:,1] , '-b', label='L2')\n",
        "#acc_ax.plot(regLimits[L1accuracyMaxIndex], L1regularizationResultsArray[:,1][L1accuracyMaxIndex], \"X\")\n",
        "#acc_ax.plot(regLimits[L2accuracyMaxIndex], L2regularizationResultsArray[:,1][L2accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Regularization Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9IUVGUJLbys",
        "colab_type": "text"
      },
      "source": [
        "Now we shorten the intervals to find the ideal value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJhLPLOLt1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1modelRegularizationResults = []\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "\n",
        "for i in range(0,100, 10):\n",
        "  mnist_conv_model_l1 = tf.keras.Sequential(name='mnist_cnn_l1'+str(i))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  for j in range(1,7):\n",
        "    mnist_conv_model_l1.add(tf.keras.layers.Dense(700, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(i/1000), name='hl_'+str(j)))\n",
        "  \n",
        "  mnist_conv_model_l1.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model_l1.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model_l1.summary()\n",
        "\n",
        "  filename = 'mnist_conv_6hl'+str(i)+'best.h5'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_model_l1_train = mnist_conv_model_l1.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model_l1.load_weights(filename)\n",
        "  loss, acc = mnist_conv_model_l1.evaluate(mnist_test_x, mnist_test_y)\n",
        "  L1modelRegularizationResults += [[loss, acc]]\n",
        "  print(L1modelRegularizationResults)\n",
        "\n",
        "for result in L1modelRegularizationResults:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvPrPcjnOb5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L2modelRegularizationResults = []\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "\n",
        "for i in range(0,100, 10):\n",
        "  mnist_conv_model_l2 = tf.keras.Sequential(name='mnist_cnn_l2'+str(i))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  for j in range(1,7):\n",
        "    mnist_conv_model_l2.add(tf.keras.layers.Dense(700, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(i/1000), name='hl_'+str(j)))\n",
        "  \n",
        "  mnist_conv_model_l2.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model_l2.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model_l2.summary()\n",
        "\n",
        "  filename = 'mnist_conv_6hl'+str(i)+'best.h5'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_model_l2_train = mnist_conv_model_l2.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model_l2.load_weights(filename)\n",
        "  loss, acc = mnist_conv_model_l2.evaluate(mnist_test_x, mnist_test_y)\n",
        "  L2modelRegularizationResults += [[loss, acc]]\n",
        "  print(L2modelRegularizationResults)\n",
        "\n",
        "for result in L2modelRegularizationResults:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpofnsvWmJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L1regularizationResultsArray = np.array(L1modelRegularizationResults)\n",
        "L2regularizationResultsArray = np.array(L2modelRegularizationResults)\n",
        "print(L1regularizationResultsArray)\n",
        "print(L2regularizationResultsArray)\n",
        "\n",
        "regLimits = [0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
        "\n",
        "L1accuracyMaxIndex = np.argmax(L1regularizationResultsArray, axis=0)[1]\n",
        "L1lossMinIndex = np.argmin(L1regularizationResultsArray, axis=0)[0]\n",
        "L2accuracyMaxIndex = np.argmax(L2regularizationResultsArray, axis=0)[1]\n",
        "L2lossMinIndex = np.argmin(L2regularizationResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Regularization Broad Analysis - Loss')\n",
        "loss_ax.plot(regLimits, L1regularizationResultsArray[:,0] , '-g', label='L1')\n",
        "loss_ax.plot(regLimits, L2regularizationResultsArray[:,0] , '-b', label='L2')\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L1regularizationResultsArray[:,0][L1lossMinIndex], \"X\")\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L2regularizationResultsArray[:,0][L2lossMinIndex], \"X\")\n",
        "\n",
        "loss_ax.set_xlabel(\"Regularization Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Regularization Broad Analysis - Accuracy')\n",
        "acc_ax.plot(regLimits, L1regularizationResultsArray[:,1] , '-g', label='L1')\n",
        "acc_ax.plot(regLimits, L2regularizationResultsArray[:,1] , '-b', label='L2')\n",
        "#acc_ax.plot(regLimits[L1accuracyMaxIndex], L1regularizationResultsArray[:,1][L1accuracyMaxIndex], \"X\")\n",
        "#acc_ax.plot(regLimits[L2accuracyMaxIndex], L2regularizationResultsArray[:,1][L2accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Regularization Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfzC54AEl5HN",
        "colab_type": "text"
      },
      "source": [
        "DROPOUT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWSWvI6Hl6E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropoutModelRegularizationResults = []\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "for i in range(10):\n",
        "  mnist_conv_drop_model = tf.keras.Sequential(name='mnist_cnn_dropout'+str(i/10))\n",
        "  mnist_conv_drop_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_drop_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_drop_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "  mnist_conv_drop_model.add(tf.keras.layers.Dropout(i/10, name='dropout0'))\n",
        "  mnist_conv_drop_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "\n",
        "  for j in range(6):\n",
        "    mnist_conv_drop_model.add(tf.keras.layers.Dense(700, activation='relu', name='hl_'+str(j)))\n",
        "  \n",
        "  mnist_conv_drop_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_drop_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_drop_model.summary()\n",
        "\n",
        "  filename = 'mnist_conv_dropout_'+str(i/10)+'best.h5'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "  mnist_conv_drop_model_train = mnist_conv_drop_model.fit(mnist_train_x[:5000], mnist_train_y[:5000], validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_drop_model.load_weights(filename)\n",
        "  loss, acc = mnist_conv_drop_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  dropoutModelRegularizationResults += [[loss, acc]]\n",
        "  print(dropoutModelRegularizationResults)\n",
        "\n",
        "for result in dropoutModelRegularizationResults:\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKTk0xDhmcdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#L1regularizationResultsArray = np.array(modelRegularizationResultsL1)\n",
        "dropoutResultsArray = np.array(dropoutModelRegularizationResults)\n",
        "\n",
        "regLimits = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "print(\"Best result:\", regLimits[np.argmax(dropoutResultsArray, axis=0)[1]])\n",
        "\n",
        "#L1accuracyMaxIndex = np.argmax(L1regularizationResultsArray, axis=0)[1]\n",
        "#L1lossMinIndex = np.argmin(L1regularizationResultsArray, axis=0)[0]\n",
        "accuracyMaxIndex = np.argmax(dropoutResultsArray, axis=0)[1]\n",
        "lossMinIndex = np.argmin(dropoutResultsArray, axis=0)[0]\n",
        "\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "loss_ax.set_title('Dropout Analysis - Loss')\n",
        "#loss_ax.plot(regLimits, L1regularizationResultsArray[:,0] , '-g', label='L1')\n",
        "loss_ax.plot(regLimits, dropoutResultsArray[:,0] , '-b', label='L2')\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L1regularizationResultsArray[:,0][L1lossMinIndex], \"X\")\n",
        "#loss_ax.plot(regLimits[lossMinIndex], L2regularizationResultsArray[:,0][L2lossMinIndex], \"X\")\n",
        "\n",
        "loss_ax.set_xlabel(\"Dropout Factor\")\n",
        "loss_ax.set_ylabel(\"Loss\")\n",
        "\n",
        "acc_ax.set_title('Regularization Detail Analysis - Accuracy')\n",
        "#acc_ax.plot(regLimits, L1regularizationResultsArray[:,1] , '-g', label='L1')\n",
        "acc_ax.plot(regLimits, dropoutResultsArray[:,1] , '-b', label='L2')\n",
        "#acc_ax.plot(regLimits[L1accuracyMaxIndex], L1regularizationResultsArray[:,1][L1accuracyMaxIndex], \"X\")\n",
        "#acc_ax.plot(regLimits[L2accuracyMaxIndex], L2regularizationResultsArray[:,1][L2accuracyMaxIndex], \"X\")\n",
        "acc_ax.set_xlabel(\"Dropout Factor\")\n",
        "acc_ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}